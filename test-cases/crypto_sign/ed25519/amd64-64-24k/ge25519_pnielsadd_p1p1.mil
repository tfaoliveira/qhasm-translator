param int crypto_sign_ed25519_amd64_64_38 = 38;
export fn crypto_sign_ed25519_amd64_64_ge25519_pnielsadd_p1p1(reg u64 rp, reg u64 pp, reg u64 qp){
	 reg u64 a0;
	 stack u64 a0_stack;
	 reg u64 a1;
	 stack u64 a1_stack;
	 reg u64 a2;
	 stack u64 a2_stack;
	 reg u64 a3;
	 stack u64 a3_stack;
	 reg u64 addt0;
	 reg u64 addt1;
	 reg u64 b0;
	 stack u64 b0_stack;
	 reg u64 b1;
	 stack u64 b1_stack;
	 reg u64 b2;
	 stack u64 b2_stack;
	 reg u64 b3;
	 stack u64 b3_stack;
	 reg u64 c0;
	 stack u64 c0_stack;
	 reg u64 c1;
	 stack u64 c1_stack;
	 reg u64 c2;
	 stack u64 c2_stack;
	 reg u64 c3;
	 stack u64 c3_stack;
	 reg bool cf;
	 reg u64 mulc;
	 reg u64 mulr4;
	 reg u64 mulr5;
	 reg u64 mulr6;
	 reg u64 mulr7;
	 reg u64 mulr8;
	 reg u64 mulrax;
	 reg u64 mulrdx;
	 reg u64 mulx0;
	 reg u64 mulx1;
	 reg u64 mulx2;
	 reg u64 mulx3;
	 reg u64 mulzero;
	 reg u64 rt0;
	 reg u64 rt1;
	 reg u64 rt2;
	 reg u64 rt3;
	 reg u64 rx0;
	 reg u64 rx1;
	 reg u64 rx2;
	 reg u64 rx3;
	 reg u64 ry0;
	 reg u64 ry1;
	 reg u64 ry2;
	 reg u64 ry3;
	 reg u64 rz0;
	 reg u64 rz1;
	 reg u64 rz2;
	 reg u64 rz3;
	 reg u64 subt0;
	 reg u64 subt1;

	qp = qp;  //qp = qp
	a0 = [pp + 4*8];  //a0 = *(uint64 *) (pp + 32)
	a1 = [pp + 5*8];  //a1 = *(uint64 *) (pp + 40)
	a2 = [pp + 6*8];  //a2 = *(uint64 *) (pp + 48)
	a3 = [pp + 7*8];  //a3 = *(uint64 *) (pp + 56)
	b0 = a0;  //b0 = a0
	b1 = a1;  //b1 = a1
	b2 = a2;  //b2 = a2
	b3 = a3;  //b3 = a3
	cf, a0 -= [pp + 0*8];  //cf? a0 -= *(uint64 *) (pp + 0)
	cf, a1 -= [pp + 1*8] - cf;  //cf? a1 -= *(uint64 *) (pp + 8) - cf; 
	cf, a2 -= [pp + 2*8] - cf;  //cf? a2 -= *(uint64 *) (pp + 16) - cf; 
	cf, a3 -= [pp + 3*8] - cf;  //cf? a3 -= *(uint64 *) (pp + 24) - cf; 
	subt0 = 0;  //subt0 = 0
	subt1 = 38;  //subt1 = 38
	subt1 = subt0 if !cf;  //subt1 = subt0 if !carry; 
	cf, a0 -= subt1;  //cf? a0 -= subt1
	cf, a1 -= subt0 - cf;  //cf? a1 -= subt0 - cf; 
	cf, a2 -= subt0 - cf;  //cf? a2 -= subt0 - cf; 
	cf, a3 -= subt0 - cf;  //cf? a3 -= subt0 - cf; 
	subt0 = subt1 if cf;  //subt0 = subt1 if carry; 
	a0 -= subt0;  //a0 -= subt0
	cf, b0 += [pp + 0*8];  //cf? b0 += *(uint64 *) (pp + 0)
	cf, b1 += [pp + 1*8] + cf;  //cf? b1 += *(uint64 *) (pp + 8) + cf;
	cf, b2 += [pp + 2*8] + cf;  //cf? b2 += *(uint64 *) (pp + 16) + cf;
	cf, b3 += [pp + 3*8] + cf;  //cf? b3 += *(uint64 *) (pp + 24) + cf;
	addt0 = 0;  //addt0 = 0
	addt1 = 38;  //addt1 = 38
	addt1 = addt0 if !cf;  //addt1 = addt0 if !carry; 
	cf, b0 += addt1;  //cf? b0 += addt1
	cf, b1 += addt0 + cf;  //cf? b1 += addt0 + cf; 
	cf, b2 += addt0 + cf;  //cf? b2 += addt0 + cf; 
	cf, b3 += addt0 + cf;  //cf? b3 += addt0 + cf; 
	addt0 = addt1 if cf;  //addt0 = addt1 if carry; 
	b0 += addt0;  //b0 += addt0
	a0_stack = a0;  //a0_stack = a0
	a1_stack = a1;  //a1_stack = a1
	a2_stack = a2;  //a2_stack = a2
	a3_stack = a3;  //a3_stack = a3
	b0_stack = b0;  //b0_stack = b0
	b1_stack = b1;  //b1_stack = b1
	b2_stack = b2;  //b2_stack = b2
	b3_stack = b3;  //b3_stack = b3
	mulr4 = 0;  //mulr4 = 0
	mulr5 = 0;  //mulr5 = 0
	mulr6 = 0;  //mulr6 = 0
	mulr7 = 0;  //mulr7 = 0
	mulx0 = a0_stack;  //mulx0 = a0_stack
	mulrax = [qp + 0*8];  //mulrax = *(uint64 *) (qp + 0)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	a0 = mulrax;  //a0 = mulrax
	a1 = mulrdx;  //a1 = mulrdx
	mulrax = [qp + 1*8];  //mulrax = *(uint64 *) (qp + 8)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, a1 += mulrax;  //cf? a1 += mulrax
	a2 = 0;  //a2 = 0
	_, a2 += mulrdx + cf;  //a2 += mulrdx + cf; 
	mulrax = [qp + 2*8];  //mulrax = *(uint64 *) (qp + 16)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, a2 += mulrax;  //cf? a2 += mulrax
	a3 = 0;  //a3 = 0
	_, a3 += mulrdx + cf;  //a3 += mulrdx + cf; 
	mulrax = [qp + 3*8];  //mulrax = *(uint64 *) (qp + 24)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, a3 += mulrax;  //cf? a3 += mulrax
	_, mulr4 += mulrdx + cf;  //mulr4 += mulrdx + cf; 
	mulx1 = a1_stack;  //mulx1 = a1_stack
	mulrax = [qp + 0*8];  //mulrax = *(uint64 *) (qp + 0)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, a1 += mulrax;  //cf? a1 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 1*8];  //mulrax = *(uint64 *) (qp + 8)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, a2 += mulrax;  //cf? a2 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, a2 += mulc;  //cf? a2 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 2*8];  //mulrax = *(uint64 *) (qp + 16)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, a3 += mulrax;  //cf? a3 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, a3 += mulc;  //cf? a3 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 3*8];  //mulrax = *(uint64 *) (qp + 24)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	_, mulr5 += mulrdx + cf;  //mulr5 += mulrdx + cf; 
	mulx2 = a2_stack;  //mulx2 = a2_stack
	mulrax = [qp + 0*8];  //mulrax = *(uint64 *) (qp + 0)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, a2 += mulrax;  //cf? a2 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 1*8];  //mulrax = *(uint64 *) (qp + 8)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, a3 += mulrax;  //cf? a3 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, a3 += mulc;  //cf? a3 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 2*8];  //mulrax = *(uint64 *) (qp + 16)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 3*8];  //mulrax = *(uint64 *) (qp + 24)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr5 += mulc;  //cf? mulr5 += mulc
	_, mulr6 += mulrdx + cf;  //mulr6 += mulrdx + cf; 
	mulx3 = a3_stack;  //mulx3 = a3_stack
	mulrax = [qp + 0*8];  //mulrax = *(uint64 *) (qp + 0)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, a3 += mulrax;  //cf? a3 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 1*8];  //mulrax = *(uint64 *) (qp + 8)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 2*8];  //mulrax = *(uint64 *) (qp + 16)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr5 += mulc;  //cf? mulr5 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 3*8];  //mulrax = *(uint64 *) (qp + 24)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr6 += mulrax;  //cf? mulr6 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr6 += mulc;  //cf? mulr6 += mulc
	_, mulr7 += mulrdx + cf;  //mulr7 += mulrdx + cf; 
	mulrax = mulr4;  //mulrax = mulr4
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	mulr4 = mulrax;  //mulr4 = mulrax
	mulrax = mulr5;  //mulrax = mulr5
	mulr5 = mulrdx;  //mulr5 = mulrdx
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	mulrax = mulr6;  //mulrax = mulr6
	mulr6 = 0;  //mulr6 = 0
	_, mulr6 += mulrdx + cf;  //mulr6 += mulrdx + cf; 
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr6 += mulrax;  //cf? mulr6 += mulrax
	mulrax = mulr7;  //mulrax = mulr7
	mulr7 = 0;  //mulr7 = 0
	_, mulr7 += mulrdx + cf;  //mulr7 += mulrdx + cf; 
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr7 += mulrax;  //cf? mulr7 += mulrax
	mulr8 = 0;  //mulr8 = 0
	_, mulr8 += mulrdx + cf;  //mulr8 += mulrdx + cf; 
	cf, a0 += mulr4;  //cf? a0 += mulr4
	cf, a1 += mulr5 + cf;  //cf? a1 += mulr5 + cf; 
	cf, a2 += mulr6 + cf;  //cf? a2 += mulr6 + cf; 
	cf, a3 += mulr7 + cf;  //cf? a3 += mulr7 + cf; 
	mulzero = 0;  //mulzero = 0
	_, mulr8 += mulzero + cf;  //mulr8 += mulzero + cf; 
	mulr8 *= 38;  //mulr8 *= 38
	cf, a0 += mulr8;  //cf? a0 += mulr8
	cf, a1 += mulzero + cf;  //cf? a1 += mulzero + cf; 
	cf, a2 += mulzero + cf;  //cf? a2 += mulzero + cf; 
	cf, a3 += mulzero + cf;  //cf? a3 += mulzero + cf; 
	_, mulzero += mulzero + cf;  //mulzero += mulzero + cf; 
	mulzero *= 38;  //mulzero *= 38
	a0 += mulzero;  //a0 += mulzero
	a0_stack = a0;  //a0_stack = a0
	a1_stack = a1;  //a1_stack = a1
	a2_stack = a2;  //a2_stack = a2
	a3_stack = a3;  //a3_stack = a3
	mulr4 = 0;  //mulr4 = 0
	mulr5 = 0;  //mulr5 = 0
	mulr6 = 0;  //mulr6 = 0
	mulr7 = 0;  //mulr7 = 0
	mulx0 = b0_stack;  //mulx0 = b0_stack
	mulrax = [qp + 4*8];  //mulrax = *(uint64 *) (qp + 32)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	rx0 = mulrax;  //rx0 = mulrax
	rx1 = mulrdx;  //rx1 = mulrdx
	mulrax = [qp + 5*8];  //mulrax = *(uint64 *) (qp + 40)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, rx1 += mulrax;  //cf? rx1 += mulrax
	rx2 = 0;  //rx2 = 0
	_, rx2 += mulrdx + cf;  //rx2 += mulrdx + cf; 
	mulrax = [qp + 6*8];  //mulrax = *(uint64 *) (qp + 48)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, rx2 += mulrax;  //cf? rx2 += mulrax
	rx3 = 0;  //rx3 = 0
	_, rx3 += mulrdx + cf;  //rx3 += mulrdx + cf; 
	mulrax = [qp + 7*8];  //mulrax = *(uint64 *) (qp + 56)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, rx3 += mulrax;  //cf? rx3 += mulrax
	_, mulr4 += mulrdx + cf;  //mulr4 += mulrdx + cf; 
	mulx1 = b1_stack;  //mulx1 = b1_stack
	mulrax = [qp + 4*8];  //mulrax = *(uint64 *) (qp + 32)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, rx1 += mulrax;  //cf? rx1 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 5*8];  //mulrax = *(uint64 *) (qp + 40)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, rx2 += mulrax;  //cf? rx2 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, rx2 += mulc;  //cf? rx2 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 6*8];  //mulrax = *(uint64 *) (qp + 48)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, rx3 += mulrax;  //cf? rx3 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, rx3 += mulc;  //cf? rx3 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 7*8];  //mulrax = *(uint64 *) (qp + 56)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	_, mulr5 += mulrdx + cf;  //mulr5 += mulrdx + cf; 
	mulx2 = b2_stack;  //mulx2 = b2_stack
	mulrax = [qp + 4*8];  //mulrax = *(uint64 *) (qp + 32)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, rx2 += mulrax;  //cf? rx2 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 5*8];  //mulrax = *(uint64 *) (qp + 40)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, rx3 += mulrax;  //cf? rx3 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, rx3 += mulc;  //cf? rx3 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 6*8];  //mulrax = *(uint64 *) (qp + 48)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 7*8];  //mulrax = *(uint64 *) (qp + 56)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr5 += mulc;  //cf? mulr5 += mulc
	_, mulr6 += mulrdx + cf;  //mulr6 += mulrdx + cf; 
	mulx3 = b3_stack;  //mulx3 = b3_stack
	mulrax = [qp + 4*8];  //mulrax = *(uint64 *) (qp + 32)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, rx3 += mulrax;  //cf? rx3 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 5*8];  //mulrax = *(uint64 *) (qp + 40)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 6*8];  //mulrax = *(uint64 *) (qp + 48)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr5 += mulc;  //cf? mulr5 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 7*8];  //mulrax = *(uint64 *) (qp + 56)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr6 += mulrax;  //cf? mulr6 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr6 += mulc;  //cf? mulr6 += mulc
	_, mulr7 += mulrdx + cf;  //mulr7 += mulrdx + cf; 
	mulrax = mulr4;  //mulrax = mulr4
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	mulr4 = mulrax;  //mulr4 = mulrax
	mulrax = mulr5;  //mulrax = mulr5
	mulr5 = mulrdx;  //mulr5 = mulrdx
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	mulrax = mulr6;  //mulrax = mulr6
	mulr6 = 0;  //mulr6 = 0
	_, mulr6 += mulrdx + cf;  //mulr6 += mulrdx + cf; 
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr6 += mulrax;  //cf? mulr6 += mulrax
	mulrax = mulr7;  //mulrax = mulr7
	mulr7 = 0;  //mulr7 = 0
	_, mulr7 += mulrdx + cf;  //mulr7 += mulrdx + cf; 
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr7 += mulrax;  //cf? mulr7 += mulrax
	mulr8 = 0;  //mulr8 = 0
	_, mulr8 += mulrdx + cf;  //mulr8 += mulrdx + cf; 
	cf, rx0 += mulr4;  //cf? rx0 += mulr4
	cf, rx1 += mulr5 + cf;  //cf? rx1 += mulr5 + cf; 
	cf, rx2 += mulr6 + cf;  //cf? rx2 += mulr6 + cf; 
	cf, rx3 += mulr7 + cf;  //cf? rx3 += mulr7 + cf; 
	mulzero = 0;  //mulzero = 0
	_, mulr8 += mulzero + cf;  //mulr8 += mulzero + cf; 
	mulr8 *= 38;  //mulr8 *= 38
	cf, rx0 += mulr8;  //cf? rx0 += mulr8
	cf, rx1 += mulzero + cf;  //cf? rx1 += mulzero + cf; 
	cf, rx2 += mulzero + cf;  //cf? rx2 += mulzero + cf; 
	cf, rx3 += mulzero + cf;  //cf? rx3 += mulzero + cf; 
	_, mulzero += mulzero + cf;  //mulzero += mulzero + cf; 
	mulzero *= 38;  //mulzero *= 38
	rx0 += mulzero;  //rx0 += mulzero
	ry0 = rx0;  //ry0 = rx0
	ry1 = rx1;  //ry1 = rx1
	ry2 = rx2;  //ry2 = rx2
	ry3 = rx3;  //ry3 = rx3
	cf, ry0 += a0_stack;  //cf? ry0 += a0_stack
	cf, ry1 += a1_stack + cf;  //cf? ry1 += a1_stack + cf; 
	cf, ry2 += a2_stack + cf;  //cf? ry2 += a2_stack + cf; 
	cf, ry3 += a3_stack + cf;  //cf? ry3 += a3_stack + cf; 
	addt0 = 0;  //addt0 = 0
	addt1 = 38;  //addt1 = 38
	addt1 = addt0 if !cf;  //addt1 = addt0 if !carry; 
	cf, ry0 += addt1;  //cf? ry0 += addt1
	cf, ry1 += addt0 + cf;  //cf? ry1 += addt0 + cf; 
	cf, ry2 += addt0 + cf;  //cf? ry2 += addt0 + cf; 
	cf, ry3 += addt0 + cf;  //cf? ry3 += addt0 + cf; 
	addt0 = addt1 if cf;  //addt0 = addt1 if carry; 
	ry0 += addt0;  //ry0 += addt0
	cf, rx0 -= a0_stack;  //cf? rx0 -= a0_stack
	cf, rx1 -= a1_stack - cf;  //cf? rx1 -= a1_stack - cf; 
	cf, rx2 -= a2_stack - cf;  //cf? rx2 -= a2_stack - cf; 
	cf, rx3 -= a3_stack - cf;  //cf? rx3 -= a3_stack - cf; 
	subt0 = 0;  //subt0 = 0
	subt1 = 38;  //subt1 = 38
	subt1 = subt0 if !cf;  //subt1 = subt0 if !carry; 
	cf, rx0 -= subt1;  //cf? rx0 -= subt1
	cf, rx1 -= subt0 - cf;  //cf? rx1 -= subt0 - cf; 
	cf, rx2 -= subt0 - cf;  //cf? rx2 -= subt0 - cf; 
	cf, rx3 -= subt0 - cf;  //cf? rx3 -= subt0 - cf; 
	subt0 = subt1 if cf;  //subt0 = subt1 if carry; 
	rx0 -= subt0;  //rx0 -= subt0
	[rp + 0*8] = rx0;  //*(uint64 *) (rp + 0) = rx0
	[rp + 1*8] = rx1;  //*(uint64 *) (rp + 8) = rx1
	[rp + 2*8] = rx2;  //*(uint64 *) (rp + 16) = rx2
	[rp + 3*8] = rx3;  //*(uint64 *) (rp + 24) = rx3
	[rp + 8*8] = ry0;  //*(uint64 *) (rp + 64) = ry0
	[rp + 9*8] = ry1;  //*(uint64 *) (rp + 72) = ry1
	[rp + 10*8] = ry2;  //*(uint64 *) (rp + 80) = ry2
	[rp + 11*8] = ry3;  //*(uint64 *) (rp + 88) = ry3
	mulr4 = 0;  //mulr4 = 0
	mulr5 = 0;  //mulr5 = 0
	mulr6 = 0;  //mulr6 = 0
	mulr7 = 0;  //mulr7 = 0
	mulx0 = [pp + 12*8];  //mulx0 = *(uint64 *) (pp + 96)
	mulrax = [qp + 12*8];  //mulrax = *(uint64 *) (qp + 96)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	c0 = mulrax;  //c0 = mulrax
	c1 = mulrdx;  //c1 = mulrdx
	mulrax = [qp + 13*8];  //mulrax = *(uint64 *) (qp + 104)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, c1 += mulrax;  //cf? c1 += mulrax
	c2 = 0;  //c2 = 0
	_, c2 += mulrdx + cf;  //c2 += mulrdx + cf; 
	mulrax = [qp + 14*8];  //mulrax = *(uint64 *) (qp + 112)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, c2 += mulrax;  //cf? c2 += mulrax
	c3 = 0;  //c3 = 0
	_, c3 += mulrdx + cf;  //c3 += mulrdx + cf; 
	mulrax = [qp + 15*8];  //mulrax = *(uint64 *) (qp + 120)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, c3 += mulrax;  //cf? c3 += mulrax
	_, mulr4 += mulrdx + cf;  //mulr4 += mulrdx + cf; 
	mulx1 = [pp + 13*8];  //mulx1 = *(uint64 *) (pp + 104)
	mulrax = [qp + 12*8];  //mulrax = *(uint64 *) (qp + 96)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, c1 += mulrax;  //cf? c1 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 13*8];  //mulrax = *(uint64 *) (qp + 104)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, c2 += mulrax;  //cf? c2 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, c2 += mulc;  //cf? c2 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 14*8];  //mulrax = *(uint64 *) (qp + 112)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, c3 += mulrax;  //cf? c3 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, c3 += mulc;  //cf? c3 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 15*8];  //mulrax = *(uint64 *) (qp + 120)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	_, mulr5 += mulrdx + cf;  //mulr5 += mulrdx + cf; 
	mulx2 = [pp + 14*8];  //mulx2 = *(uint64 *) (pp + 112)
	mulrax = [qp + 12*8];  //mulrax = *(uint64 *) (qp + 96)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, c2 += mulrax;  //cf? c2 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 13*8];  //mulrax = *(uint64 *) (qp + 104)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, c3 += mulrax;  //cf? c3 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, c3 += mulc;  //cf? c3 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 14*8];  //mulrax = *(uint64 *) (qp + 112)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 15*8];  //mulrax = *(uint64 *) (qp + 120)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr5 += mulc;  //cf? mulr5 += mulc
	_, mulr6 += mulrdx + cf;  //mulr6 += mulrdx + cf; 
	mulx3 = [pp + 15*8];  //mulx3 = *(uint64 *) (pp + 120)
	mulrax = [qp + 12*8];  //mulrax = *(uint64 *) (qp + 96)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, c3 += mulrax;  //cf? c3 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 13*8];  //mulrax = *(uint64 *) (qp + 104)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 14*8];  //mulrax = *(uint64 *) (qp + 112)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr5 += mulc;  //cf? mulr5 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 15*8];  //mulrax = *(uint64 *) (qp + 120)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr6 += mulrax;  //cf? mulr6 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr6 += mulc;  //cf? mulr6 += mulc
	_, mulr7 += mulrdx + cf;  //mulr7 += mulrdx + cf; 
	mulrax = mulr4;  //mulrax = mulr4
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	mulr4 = mulrax;  //mulr4 = mulrax
	mulrax = mulr5;  //mulrax = mulr5
	mulr5 = mulrdx;  //mulr5 = mulrdx
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	mulrax = mulr6;  //mulrax = mulr6
	mulr6 = 0;  //mulr6 = 0
	_, mulr6 += mulrdx + cf;  //mulr6 += mulrdx + cf; 
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr6 += mulrax;  //cf? mulr6 += mulrax
	mulrax = mulr7;  //mulrax = mulr7
	mulr7 = 0;  //mulr7 = 0
	_, mulr7 += mulrdx + cf;  //mulr7 += mulrdx + cf; 
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr7 += mulrax;  //cf? mulr7 += mulrax
	mulr8 = 0;  //mulr8 = 0
	_, mulr8 += mulrdx + cf;  //mulr8 += mulrdx + cf; 
	cf, c0 += mulr4;  //cf? c0 += mulr4
	cf, c1 += mulr5 + cf;  //cf? c1 += mulr5 + cf; 
	cf, c2 += mulr6 + cf;  //cf? c2 += mulr6 + cf; 
	cf, c3 += mulr7 + cf;  //cf? c3 += mulr7 + cf; 
	mulzero = 0;  //mulzero = 0
	_, mulr8 += mulzero + cf;  //mulr8 += mulzero + cf; 
	mulr8 *= 38;  //mulr8 *= 38
	cf, c0 += mulr8;  //cf? c0 += mulr8
	cf, c1 += mulzero + cf;  //cf? c1 += mulzero + cf; 
	cf, c2 += mulzero + cf;  //cf? c2 += mulzero + cf; 
	cf, c3 += mulzero + cf;  //cf? c3 += mulzero + cf; 
	_, mulzero += mulzero + cf;  //mulzero += mulzero + cf; 
	mulzero *= 38;  //mulzero *= 38
	c0 += mulzero;  //c0 += mulzero
	c0_stack = c0;  //c0_stack = c0
	c1_stack = c1;  //c1_stack = c1
	c2_stack = c2;  //c2_stack = c2
	c3_stack = c3;  //c3_stack = c3
	mulr4 = 0;  //mulr4 = 0
	mulr5 = 0;  //mulr5 = 0
	mulr6 = 0;  //mulr6 = 0
	mulr7 = 0;  //mulr7 = 0
	mulx0 = [pp + 8*8];  //mulx0 = *(uint64 *) (pp + 64)
	mulrax = [qp + 8*8];  //mulrax = *(uint64 *) (qp + 64)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	rt0 = mulrax;  //rt0 = mulrax
	rt1 = mulrdx;  //rt1 = mulrdx
	mulrax = [qp + 9*8];  //mulrax = *(uint64 *) (qp + 72)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, rt1 += mulrax;  //cf? rt1 += mulrax
	rt2 = 0;  //rt2 = 0
	_, rt2 += mulrdx + cf;  //rt2 += mulrdx + cf; 
	mulrax = [qp + 10*8];  //mulrax = *(uint64 *) (qp + 80)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, rt2 += mulrax;  //cf? rt2 += mulrax
	rt3 = 0;  //rt3 = 0
	_, rt3 += mulrdx + cf;  //rt3 += mulrdx + cf; 
	mulrax = [qp + 11*8];  //mulrax = *(uint64 *) (qp + 88)
	mulrdx, mulrax = mulrax * mulx0;  //(uint128) mulrdx mulrax = mulrax * mulx0
	cf, rt3 += mulrax;  //cf? rt3 += mulrax
	_, mulr4 += mulrdx + cf;  //mulr4 += mulrdx + cf; 
	mulx1 = [pp + 9*8];  //mulx1 = *(uint64 *) (pp + 72)
	mulrax = [qp + 8*8];  //mulrax = *(uint64 *) (qp + 64)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, rt1 += mulrax;  //cf? rt1 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 9*8];  //mulrax = *(uint64 *) (qp + 72)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, rt2 += mulrax;  //cf? rt2 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, rt2 += mulc;  //cf? rt2 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 10*8];  //mulrax = *(uint64 *) (qp + 80)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, rt3 += mulrax;  //cf? rt3 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, rt3 += mulc;  //cf? rt3 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 11*8];  //mulrax = *(uint64 *) (qp + 88)
	mulrdx, mulrax = mulrax * mulx1;  //(uint128) mulrdx mulrax = mulrax * mulx1
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	_, mulr5 += mulrdx + cf;  //mulr5 += mulrdx + cf; 
	mulx2 = [pp + 10*8];  //mulx2 = *(uint64 *) (pp + 80)
	mulrax = [qp + 8*8];  //mulrax = *(uint64 *) (qp + 64)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, rt2 += mulrax;  //cf? rt2 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 9*8];  //mulrax = *(uint64 *) (qp + 72)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, rt3 += mulrax;  //cf? rt3 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, rt3 += mulc;  //cf? rt3 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 10*8];  //mulrax = *(uint64 *) (qp + 80)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 11*8];  //mulrax = *(uint64 *) (qp + 88)
	mulrdx, mulrax = mulrax * mulx2;  //(uint128) mulrdx mulrax = mulrax * mulx2
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr5 += mulc;  //cf? mulr5 += mulc
	_, mulr6 += mulrdx + cf;  //mulr6 += mulrdx + cf; 
	mulx3 = [pp + 11*8];  //mulx3 = *(uint64 *) (pp + 88)
	mulrax = [qp + 8*8];  //mulrax = *(uint64 *) (qp + 64)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, rt3 += mulrax;  //cf? rt3 += mulrax
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 9*8];  //mulrax = *(uint64 *) (qp + 72)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr4 += mulrax;  //cf? mulr4 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr4 += mulc;  //cf? mulr4 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 10*8];  //mulrax = *(uint64 *) (qp + 80)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr5 += mulc;  //cf? mulr5 += mulc
	mulc = 0;  //mulc = 0
	_, mulc += mulrdx + cf;  //mulc += mulrdx + cf; 
	mulrax = [qp + 11*8];  //mulrax = *(uint64 *) (qp + 88)
	mulrdx, mulrax = mulrax * mulx3;  //(uint128) mulrdx mulrax = mulrax * mulx3
	cf, mulr6 += mulrax;  //cf? mulr6 += mulrax
	_, mulrdx += 0 + cf;  // mulrdx += 0 + cf; 
	cf, mulr6 += mulc;  //cf? mulr6 += mulc
	_, mulr7 += mulrdx + cf;  //mulr7 += mulrdx + cf; 
	mulrax = mulr4;  //mulrax = mulr4
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	mulr4 = mulrax;  //mulr4 = mulrax
	mulrax = mulr5;  //mulrax = mulr5
	mulr5 = mulrdx;  //mulr5 = mulrdx
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr5 += mulrax;  //cf? mulr5 += mulrax
	mulrax = mulr6;  //mulrax = mulr6
	mulr6 = 0;  //mulr6 = 0
	_, mulr6 += mulrdx + cf;  //mulr6 += mulrdx + cf; 
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr6 += mulrax;  //cf? mulr6 += mulrax
	mulrax = mulr7;  //mulrax = mulr7
	mulr7 = 0;  //mulr7 = 0
	_, mulr7 += mulrdx + cf;  //mulr7 += mulrdx + cf; 
	mulrdx, mulrax = mulrax * crypto_sign_ed25519_amd64_64_38;  //(uint128) mulrdx mulrax = mulrax * *(uint64 *) &crypto_sign_ed25519_amd64_64_38
	cf, mulr7 += mulrax;  //cf? mulr7 += mulrax
	mulr8 = 0;  //mulr8 = 0
	_, mulr8 += mulrdx + cf;  //mulr8 += mulrdx + cf; 
	cf, rt0 += mulr4;  //cf? rt0 += mulr4
	cf, rt1 += mulr5 + cf;  //cf? rt1 += mulr5 + cf; 
	cf, rt2 += mulr6 + cf;  //cf? rt2 += mulr6 + cf; 
	cf, rt3 += mulr7 + cf;  //cf? rt3 += mulr7 + cf; 
	mulzero = 0;  //mulzero = 0
	_, mulr8 += mulzero + cf;  //mulr8 += mulzero + cf; 
	mulr8 *= 38;  //mulr8 *= 38
	cf, rt0 += mulr8;  //cf? rt0 += mulr8
	cf, rt1 += mulzero + cf;  //cf? rt1 += mulzero + cf; 
	cf, rt2 += mulzero + cf;  //cf? rt2 += mulzero + cf; 
	cf, rt3 += mulzero + cf;  //cf? rt3 += mulzero + cf; 
	_, mulzero += mulzero + cf;  //mulzero += mulzero + cf; 
	mulzero *= 38;  //mulzero *= 38
	rt0 += mulzero;  //rt0 += mulzero
	cf, rt0 += rt0;  //cf? rt0 += rt0
	cf, rt1 += rt1 + cf;  //cf? rt1 += rt1 + cf; 
	cf, rt2 += rt2 + cf;  //cf? rt2 += rt2 + cf; 
	cf, rt3 += rt3 + cf;  //cf? rt3 += rt3 + cf; 
	addt0 = 0;  //addt0 = 0
	addt1 = 38;  //addt1 = 38
	addt1 = addt0 if !cf;  //addt1 = addt0 if !carry; 
	cf, rt0 += addt1;  //cf? rt0 += addt1
	cf, rt1 += addt0 + cf;  //cf? rt1 += addt0 + cf; 
	cf, rt2 += addt0 + cf;  //cf? rt2 += addt0 + cf; 
	cf, rt3 += addt0 + cf;  //cf? rt3 += addt0 + cf; 
	addt0 = addt1 if cf;  //addt0 = addt1 if carry; 
	rt0 += addt0;  //rt0 += addt0
	rz0 = rt0;  //rz0 = rt0
	rz1 = rt1;  //rz1 = rt1
	rz2 = rt2;  //rz2 = rt2
	rz3 = rt3;  //rz3 = rt3
	cf, rz0 += c0_stack;  //cf? rz0 += c0_stack
	cf, rz1 += c1_stack + cf;  //cf? rz1 += c1_stack + cf; 
	cf, rz2 += c2_stack + cf;  //cf? rz2 += c2_stack + cf; 
	cf, rz3 += c3_stack + cf;  //cf? rz3 += c3_stack + cf; 
	addt0 = 0;  //addt0 = 0
	addt1 = 38;  //addt1 = 38
	addt1 = addt0 if !cf;  //addt1 = addt0 if !carry; 
	cf, rz0 += addt1;  //cf? rz0 += addt1
	cf, rz1 += addt0 + cf;  //cf? rz1 += addt0 + cf; 
	cf, rz2 += addt0 + cf;  //cf? rz2 += addt0 + cf; 
	cf, rz3 += addt0 + cf;  //cf? rz3 += addt0 + cf; 
	addt0 = addt1 if cf;  //addt0 = addt1 if carry; 
	rz0 += addt0;  //rz0 += addt0
	cf, rt0 -= c0_stack;  //cf? rt0 -= c0_stack
	cf, rt1 -= c1_stack - cf;  //cf? rt1 -= c1_stack - cf; 
	cf, rt2 -= c2_stack - cf;  //cf? rt2 -= c2_stack - cf; 
	cf, rt3 -= c3_stack - cf;  //cf? rt3 -= c3_stack - cf; 
	subt0 = 0;  //subt0 = 0
	subt1 = 38;  //subt1 = 38
	subt1 = subt0 if !cf;  //subt1 = subt0 if !carry; 
	cf, rt0 -= subt1;  //cf? rt0 -= subt1
	cf, rt1 -= subt0 - cf;  //cf? rt1 -= subt0 - cf; 
	cf, rt2 -= subt0 - cf;  //cf? rt2 -= subt0 - cf; 
	cf, rt3 -= subt0 - cf;  //cf? rt3 -= subt0 - cf; 
	subt0 = subt1 if cf;  //subt0 = subt1 if carry; 
	rt0 -= subt0;  //rt0 -= subt0
	[rp + 4*8] = rz0;  //*(uint64 *) (rp + 32) = rz0
	[rp + 5*8] = rz1;  //*(uint64 *) (rp + 40) = rz1
	[rp + 6*8] = rz2;  //*(uint64 *) (rp + 48) = rz2
	[rp + 7*8] = rz3;  //*(uint64 *) (rp + 56) = rz3
	[rp + 12*8] = rt0;  //*(uint64 *) (rp + 96) = rt0
	[rp + 13*8] = rt1;  //*(uint64 *) (rp + 104) = rt1
	[rp + 14*8] = rt2;  //*(uint64 *) (rp + 112) = rt2
	[rp + 15*8] = rt3;  //*(uint64 *) (rp + 120) = rt3
	return;
}


